{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab3fc3db",
   "metadata": {},
   "source": [
    "* Criado por: Gabriel Quintella\n",
    "* Data Criação: 24.01.2023\n",
    "* Data Última Modificação: 29.01.2023\n",
    "* Repositório: https://github.com/dbaassists/Projeto-KB-Spark/blob/main/Projeto%20KB%20Spark.ipynb\n",
    "\n",
    "DESCRIÇÃO DO PROJETO\n",
    "\n",
    "Criar uma base de conhecimento (KB) com comandos pyspark.\n",
    "\n",
    "*  Dia 1 - 24.01.2023 - Lançamento do Projeto;\n",
    "*  Dia 2 - 26.01.2023 - Aprimoramento do Projeto com melhoria nos exemplos criados;\n",
    "*  Dia 3 - 27.01.2023 - Aprimoramento do Projeto com melhoria nos exemplos criados;\n",
    "*  Dia 4 - 28.01.2023 - Aprimoramento do Projeto com melhoria nos exemplos criados;\n",
    "*  Dia 5 - 29.01.2023 - Aprimoramento do Projeto com melhoria nos exemplos criados;\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe5cefe",
   "metadata": {},
   "source": [
    " Sumário\n",
    "\n",
    "* 01 - Instalação da Biblioteca PySpark\n",
    "* 02 - Definição de Bibliotecas\n",
    "* 03 - Importando Arquivo CSV\n",
    "* 04 - Transformando o DataFrame Spark em Tabela Temporária\n",
    "* 05 - Consultando a Estrutura do DataFrame Spark\n",
    "* 06 - Lendo a Tabela e Transformando em outro DataFrame Spark\n",
    "* 07 - Convertendo o DataType de uma Coluna de um DataFrame Spark\n",
    "* 08 - Convertendo o DataType e Criando uma nova Coluna de um DataFrame Spark\n",
    "* 09 - Renomeando uma Coluna em DataFrame Spark\n",
    "* 10 - Renomeando Várias Colunas em DataFrame Spark\n",
    "* 11 - Ordenando um DataFrame Spark\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f74811",
   "metadata": {},
   "source": [
    "# 01 - Instalação da Biblioteca PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbd34d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffca164f",
   "metadata": {},
   "source": [
    "# 02 - Definição de Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44ba938",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import pyspark.sql.functions as F #import explode_outer, col\n",
    "from pyspark.sql.types import *\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark import SparkConf\n",
    "from pyspark import SparkContext\n",
    "import urllib\n",
    "from sqlalchemy import __version__ as sa_version, create_engine, text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601c08c7",
   "metadata": {},
   "source": [
    "# 03 - Importando Arquivo CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48492cb3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "arquivo = '../ProjetoSparkKB/Dados/Candidato/consulta_cand_2022_BRASIL.csv'\n",
    "\n",
    "df = spark.read.csv(arquivo, sep=';',header=True)\n",
    "\n",
    "#df.select('DT_GERACAO').show()\n",
    "\n",
    "df.show(2,truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8511ac4",
   "metadata": {},
   "source": [
    "# 03.1 - Importando Arquivo CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07c5f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivo = '../ProjetoSparkKB/Dados/Candidato/consulta_cand_2022_BRASIL.csv'\n",
    "\n",
    "dfExemplo2 = spark.read.format(\"csv\").load(arquivo)\n",
    "    \n",
    "dfExemplo2.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e755543",
   "metadata": {},
   "source": [
    "# 03.2 - Importando Arquivo CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f47db82",
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivo = '../ProjetoSparkKB/Dados/Candidato/consulta_cand_2022_BRASIL.csv'\n",
    "\n",
    "dfExemplo3 = spark.read.option(\"inferSchema\",False) \\\n",
    "                .option(\"delimiter\",\";\") \\\n",
    "                .option(\"header\",True) \\\n",
    "                .csv(arquivo)\n",
    "\n",
    "dfExemplo3.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfb1ab0",
   "metadata": {},
   "source": [
    "# 03.3 - Importando Arquivo CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe817b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivo = '../ProjetoSparkKB/Dados/Candidato/consulta_cand_2022_BRASIL.csv'\n",
    "\n",
    "dfExemplo04 = spark.read.options(header='True', inferSchema='True', delimiter=';') \\\n",
    "  .csv(arquivo)\n",
    "\n",
    "dfExemplo04.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a837590",
   "metadata": {},
   "source": [
    "# 03.4 - Importando Arquivo CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee866c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivo = '../ProjetoSparkKB/Dados/IndicadorSegurancaPublica/indicador_homocidio.csv'\n",
    "\n",
    "df3 = spark.read.options(header='True', inferSchema='True', delimiter=';').csv(arquivo)\n",
    "\n",
    "df3.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f977dd55",
   "metadata": {},
   "source": [
    "# 03.5 - Importando Arquivo CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d73ae5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivo = '../ProjetoSparkKB/Dados/IndicadorSegurancaPublica/indicador_homocidio.csv'\n",
    "\n",
    "df3 = spark.read.options(header='True', inferSchema='True', delimiter=';').csv(arquivo)\n",
    "\n",
    "df3.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2264089",
   "metadata": {},
   "source": [
    "# 03.6 - Importando Arquivo CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c643da4b",
   "metadata": {},
   "source": [
    "** Documentação: https://sqlrelease.com/spark-read-file-with-special-characters-using-pyspark\n",
    "\n",
    "** Documentação: https://sparkbyexamples.com/pyspark/pyspark-sql-types-datatype-with-examples/\n",
    "\n",
    "** Documentação: https://spark.apache.org/docs/latest/sql-ref-datatypes.html\n",
    "\n",
    "** Documentação: https://sparkbyexamples.com/pyspark/pyspark-date_format-convert-date-to-string-format/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe849d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivo = '../ProjetoSparkKB/Dados/IndicadorSegurancaPublica/indicador_homocidio.csv'\n",
    "\n",
    "\n",
    "schema = StructType() \\\n",
    "      .add(\"CodUf\",StringType(),True) \\\n",
    "      .add(\"TipoCrime\",StringType(),True) \\\n",
    "      .add(\"Quantidade\",IntegerType(),True) \\\n",
    "      .add(\"Data\",DateType(),True) \\\n",
    "\n",
    "\n",
    "df_with_schema = spark.read.options(header='True', inferSchema='False', delimiter=';', encoding=\"windows-1252\") \\\n",
    "      .schema(schema) \\\n",
    "      .csv(arquivo)\n",
    "\n",
    "df_with_schema.printSchema()\n",
    "\n",
    "df_with_schema.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd27b7d5",
   "metadata": {},
   "source": [
    "# 04 - Trabalhando com Datas - Converte coluna String (DD/MM/AAA) para Date (AAAAMMDD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15ec53e",
   "metadata": {},
   "source": [
    "* Trabalhando com Datas\n",
    "\n",
    "** Documentação: https://spark.apache.org/docs/latest/sql-ref-datetime-pattern.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a5f83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "arquivo = '../ProjetoSparkKB/Dados/IndicadorSegurancaPublica/indicador_homocidio_2.csv'\n",
    "\n",
    "schema = StructType() \\\n",
    "      .add(\"CodUf\",StringType(),True) \\\n",
    "      .add(\"TipoCrime\",StringType(),True) \\\n",
    "      .add(\"Quantidade\",IntegerType(),True) \\\n",
    "      .add(\"Data\",StringType(),True) \\\n",
    "\n",
    "df_with_schema2 = spark.read.options(header='True', inferSchema='False', delimiter=';', encoding=\"windows-1252\") \\\n",
    "      .schema(schema) \\\n",
    "      .csv(arquivo)\n",
    "\n",
    "df_with_schema2.show()\n",
    "\n",
    "df_with_schema2 = df_with_schema2.withColumn('Data', to_date(date_format(unix_timestamp(df_with_schema2.Data , \"dd/mm/yyyy\").cast(\"timestamp\"),\"yyyy-mm-dd\")))\n",
    "\n",
    "df_with_schema2.printSchema()\n",
    "\n",
    "df_with_schema2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c36d587",
   "metadata": {},
   "source": [
    "# 04.1 - Trabalhando com Datas - A partir de uma coluna de Data, criar outra de Ano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe7b271",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_with_schema2 = df_with_schema2.withColumn(\"Ano\", date_format(col(\"Data\"), \"y\"))\n",
    "\n",
    "\n",
    "df_with_schema2.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6129bc",
   "metadata": {},
   "source": [
    "# 04.2 - Trabalhando com Datas - A partir de uma coluna de Data, criar outra de Mês"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4736e507",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_with_schema2 = df_with_schema2.withColumn(\"NumMes\", date_format(col(\"Data\"), \"M\"))\n",
    "\n",
    "df_with_schema2 = df_with_schema2.withColumn(\"NomMes\", date_format(col(\"Data\"), \"L\"))\n",
    "\n",
    "\n",
    "df_with_schema2.printSchema()\n",
    "\n",
    "df_with_schema2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28ce65f",
   "metadata": {},
   "source": [
    "# 04.3 - Trabalhando com Datas - A partir de uma coluna de Data, criar outra de Dia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d2791d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df_with_schema2 = df_with_schema2.withColumn(\"NumDiaAno\", date_format(col(\"Data\"), \"D\"))\n",
    "\n",
    "df_with_schema2 = df_with_schema2.withColumn(\"NumDiaMes\", date_format(col(\"Data\"), \"d\"))\n",
    "\n",
    "df_with_schema2.printSchema()\n",
    "\n",
    "df_with_schema2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f9d970",
   "metadata": {},
   "source": [
    "# 05 - Trabalhando com Arquivos Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b0c45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#arquivoDestino = '../ProjetoSparkKB/Dados/Parquet/indicador_homocidio.parquet'\n",
    "\n",
    "#df_with_schema3.write.mode(\"overwrite\").parquet(arquivoDestino)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1716685",
   "metadata": {},
   "source": [
    "# 06 - Comando Semelhante ao DataFrame.info() do Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774338eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_schema3.summary().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b440ad",
   "metadata": {},
   "source": [
    "# 04 - Transformando o DataFrame Spark em Tabela Temporária"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157f47a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('teste')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9b9a6e",
   "metadata": {},
   "source": [
    "# 05 - Consultando a Estrutura do DataFrame Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1519c70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c403b4",
   "metadata": {},
   "source": [
    "# 06 - Lendo a Tabela e Transformando em outro DataFrame Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321f7f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = spark.sql(\"\"\"\n",
    "SELECT DT_GERACAO \n",
    "FROM TESTE\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3dcbab4",
   "metadata": {},
   "source": [
    "# 07 - Convertendo o DataType de uma Coluna de um DataFrame Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adee011",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.withColumn(\"DT_GERACAO\", df2[\"DT_GERACAO\"].cast(\"timestamp\")).printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81ec42d",
   "metadata": {},
   "source": [
    "# 08 - Convertendo o DataType e Criando uma nova Coluna de um DataFrame Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7358983",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.withColumn(\"DTGERACAO\", df2[\"DT_GERACAO\"].cast(\"timestamp\")).printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d56251",
   "metadata": {},
   "source": [
    "# 09 - Renomeando uma Coluna em DataFrame Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6004d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.withColumnRenamed(\"DT_GERACAO\",\"DT_GERACAO2\").printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81929c4",
   "metadata": {},
   "source": [
    "# 10 - Renomeando Várias Colunas em DataFrame Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce058d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = spark.sql(\"\"\"\n",
    "SELECT DT_GERACAO , HH_GERACAO\n",
    "FROM TESTE\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbf44c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df3.withColumnRenamed(\"DT_GERACAO\",\"DtGeracao\") \\\n",
    "    .withColumnRenamed(\"HH_GERACAO\",\"HrGeracao\")\n",
    "df3.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2902ee0",
   "metadata": {},
   "source": [
    "# 11 - Ordenando um DataFrame Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a580782b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = spark.sql(\"\"\"\n",
    "SELECT SG_UF , NM_URNA_CANDIDATO\n",
    "FROM TESTE\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65525fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0049a15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.sort(\"SG_UF\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1346d0",
   "metadata": {},
   "source": [
    "# 11.1 - Ordenando um DataFrame Spark por Várias Colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c228be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.sort(\"SG_UF\",\"NM_URNA_CANDIDATO\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a99ca4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df4.sort(col(\"SG_UF\"),col(\"NM_URNA_CANDIDATO\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0616911e",
   "metadata": {},
   "source": [
    "# 12 - Agrupando um DataFrame Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adea42a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.groupBy(\"SG_UF\").count().show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b464158c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = spark.sql(\"\"\"\n",
    "SELECT SG_UF , NM_URNA_CANDIDATO, SQ_CANDIDATO\n",
    "FROM TESTE\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5593e7a3",
   "metadata": {},
   "source": [
    "# 13 - Funções de Agrupamento (Count(), Sum(), Min(), Max() e Mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b043be67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.groupBy(\"SG_UF\") \\\n",
    "    .agg(count(\"SQ_CANDIDATO\").alias(\"count_SQ_CANDIDATO\"), \\\n",
    "         sum(\"SQ_CANDIDATO\").alias(\"sum_SQ_CANDIDATO\"), \\\n",
    "         avg(\"SQ_CANDIDATO\").alias(\"avg_SQ_CANDIDATO\"), \\\n",
    "         min(\"SQ_CANDIDATO\").alias(\"min_SQ_CANDIDATO\"), \\\n",
    "         max(\"SQ_CANDIDATO\").alias(\"max_SQ_CANDIDATO\") \\\n",
    "     ) \\\n",
    "    .show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
