{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab3fc3db",
   "metadata": {},
   "source": [
    "* Criado por: Gabriel Quintella\n",
    "* Data Criação: 24.01.2023\n",
    "* Data Última Modificação: 30.01.2023\n",
    "* Repositório: https://github.com/dbaassists/Projeto-KB-Spark/blob/main/Projeto%20KB%20Spark.ipynb\n",
    "\n",
    "DESCRIÇÃO DO PROJETO\n",
    "\n",
    "Criar uma base de conhecimento (KB) com comandos pyspark.\n",
    "\n",
    "*  Dia 1 - 24.01.2023 - Lançamento do Projeto;\n",
    "*  Dia 2 - 26.01.2023 - Aprimoramento do Projeto com melhoria nos exemplos criados;\n",
    "*  Dia 3 - 27.01.2023 - Aprimoramento do Projeto com melhoria nos exemplos criados;\n",
    "*  Dia 4 - 28.01.2023 - Aprimoramento do Projeto com melhoria nos exemplos criados;\n",
    "*  Dia 5 - 29.01.2023 - Aprimoramento do Projeto com melhoria nos exemplos criados;\n",
    "*  Dia 6 - 30.01.2023 - Aprimoramento do Projeto com melhoria nos exemplos criados;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe5cefe",
   "metadata": {},
   "source": [
    " Sumário\n",
    "\n",
    "* 01 - Instalação da Biblioteca PySpark\n",
    "* 02 - Definição de Bibliotecas\n",
    "* 03 - Métodos de Importação de Arquivos CSV\n",
    "* 04 - Transformando o DataFrame Spark em Tabela Temporária\n",
    "* 05 - Consultando a Estrutura do DataFrame Spark\n",
    "* 06 - Lendo a Tabela e Transformando em outro DataFrame Spark\n",
    "* 07 - Convertendo o DataType de uma Coluna de um DataFrame Spark\n",
    "* 08 - Convertendo o DataType e Criando uma nova Coluna de um DataFrame Spark\n",
    "* 09 - Renomeando uma Coluna em DataFrame Spark\n",
    "* 10 - Renomeando Várias Colunas em DataFrame Spark\n",
    "* 11 - Ordenando um DataFrame Spark\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f74811",
   "metadata": {},
   "source": [
    "# 01 - Instalação da Biblioteca PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbd34d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffca164f",
   "metadata": {},
   "source": [
    "# 02 - Definição de Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44ba938",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import pyspark.sql.functions as F #import explode_outer, col\n",
    "from pyspark.sql.types import *\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark import SparkConf\n",
    "from pyspark import SparkContext\n",
    "import urllib\n",
    "from sqlalchemy import __version__ as sa_version, create_engine, text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601c08c7",
   "metadata": {},
   "source": [
    "# 03 - Métodos de Importação de Arquivos CSV\n",
    "\n",
    "* A CSV dataset is pointed to by path.\n",
    "* The path can be either a single CSV file or a directory of CSV files\n",
    "* path = \"examples/src/main/resources/people.csv\"\n",
    "\n",
    "df = spark.read.csv(path)\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5c1984",
   "metadata": {},
   "source": [
    "# 03.1 - Importando Arquivo CSV de forma FULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232c57aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "arquivo = '../ProjetoSparkKB/Dados/Candidato/consulta_cand_2022_BRASIL.csv'\n",
    "\n",
    "df = spark.read.csv(arquivo)\n",
    "\n",
    "df.show(2,truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d88f86",
   "metadata": {},
   "source": [
    "# 03.2 - Importando Arquivo CSV Definindo o Delimitador de Colunas\n",
    "\n",
    "* Read a csv with delimiter, the default delimiter is \",\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25128308",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "arquivo = '../ProjetoSparkKB/Dados/Candidato/consulta_cand_2022_BRASIL.csv'\n",
    "\n",
    "df = spark.read.option('delimiter',';').csv(arquivo)\n",
    "\n",
    "#df.select('DT_GERACAO').show()\n",
    "\n",
    "df.show(2,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "cdb319f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o1355.csv.\n: org.apache.spark.SparkException: Job aborted.\r\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.jobAbortedError(QueryExecutionErrors.scala:651)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:278)\r\n\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:186)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:113)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:111)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.executeCollect(commands.scala:125)\r\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:98)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:109)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:169)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:95)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\r\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\r\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:94)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:584)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:176)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:584)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:30)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:560)\r\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:94)\r\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:81)\r\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:79)\r\n\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:116)\r\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:860)\r\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:390)\r\n\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:363)\r\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:239)\r\n\tat org.apache.spark.sql.DataFrameWriter.csv(DataFrameWriter.scala:851)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\nCaused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 136.0 failed 1 times, most recent failure: Lost task 0.0 in stage 136.0 (TID 150) (DESKTOP-GT679GD executor driver): java.io.IOException: (null) entry in command string: null chmod 0644 C:\\tmp\\spark_output\\zipcodes\\_temporary\\0\\_temporary\\attempt_2023013020081630551652960918700_0136_m_000000_150\\part-00000-f9bf5b6c-54b7-4bb2-848d-2bd49ac00cfb-c000.csv\r\n\tat org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)\r\n\tat org.apache.hadoop.util.Shell.execCommand(Shell.java:869)\r\n\tat org.apache.hadoop.util.Shell.execCommand(Shell.java:852)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:733)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:225)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:209)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.createOutputStreamWithMode(RawLocalFileSystem.java:307)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:296)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:328)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:398)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:461)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:440)\r\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:911)\r\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:892)\r\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:789)\r\n\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStream(CodecStreams.scala:81)\r\n\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStreamWriter(CodecStreams.scala:92)\r\n\tat org.apache.spark.sql.execution.datasources.csv.CsvOutputWriter.<init>(CsvOutputWriter.scala:38)\r\n\tat org.apache.spark.sql.execution.datasources.csv.CSVFileFormat$$anon$1.newInstance(CSVFileFormat.scala:84)\r\n\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.newOutputWriter(FileFormatDataWriter.scala:161)\r\n\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.<init>(FileFormatDataWriter.scala:146)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:317)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$21(FileFormatWriter.scala:256)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:136)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2672)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2608)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2607)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2607)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1182)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1182)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1182)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2860)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:952)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2228)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:245)\r\n\t... 42 more\r\nCaused by: java.io.IOException: (null) entry in command string: null chmod 0644 C:\\tmp\\spark_output\\zipcodes\\_temporary\\0\\_temporary\\attempt_2023013020081630551652960918700_0136_m_000000_150\\part-00000-f9bf5b6c-54b7-4bb2-848d-2bd49ac00cfb-c000.csv\r\n\tat org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)\r\n\tat org.apache.hadoop.util.Shell.execCommand(Shell.java:869)\r\n\tat org.apache.hadoop.util.Shell.execCommand(Shell.java:852)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:733)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:225)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:209)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.createOutputStreamWithMode(RawLocalFileSystem.java:307)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:296)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:328)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:398)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:461)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:440)\r\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:911)\r\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:892)\r\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:789)\r\n\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStream(CodecStreams.scala:81)\r\n\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStreamWriter(CodecStreams.scala:92)\r\n\tat org.apache.spark.sql.execution.datasources.csv.CsvOutputWriter.<init>(CsvOutputWriter.scala:38)\r\n\tat org.apache.spark.sql.execution.datasources.csv.CSVFileFormat$$anon$1.newInstance(CSVFileFormat.scala:84)\r\n\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.newOutputWriter(FileFormatDataWriter.scala:161)\r\n\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.<init>(FileFormatDataWriter.scala:146)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:317)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$21(FileFormatWriter.scala:256)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:136)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\t... 1 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[1;32mIn [137]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mheader\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcsv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/tmp/spark_output/zipcodes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pyspark\\sql\\readwriter.py:1240\u001b[0m, in \u001b[0;36mDataFrameWriter.csv\u001b[1;34m(self, path, mode, compression, sep, quote, escape, header, nullValue, escapeQuotes, quoteAll, dateFormat, timestampFormat, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, charToEscapeQuoteEscaping, encoding, emptyValue, lineSep)\u001b[0m\n\u001b[0;32m   1221\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode(mode)\n\u001b[0;32m   1222\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_opts(\n\u001b[0;32m   1223\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[0;32m   1224\u001b[0m     sep\u001b[38;5;241m=\u001b[39msep,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1238\u001b[0m     lineSep\u001b[38;5;241m=\u001b[39mlineSep,\n\u001b[0;32m   1239\u001b[0m )\n\u001b[1;32m-> 1240\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcsv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\py4j\\java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pyspark\\sql\\utils.py:190\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 190\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    191\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    192\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o1355.csv.\n: org.apache.spark.SparkException: Job aborted.\r\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.jobAbortedError(QueryExecutionErrors.scala:651)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:278)\r\n\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:186)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:113)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:111)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.executeCollect(commands.scala:125)\r\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:98)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:109)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:169)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:95)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\r\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\r\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:94)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:584)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:176)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:584)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:30)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:560)\r\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:94)\r\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:81)\r\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:79)\r\n\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:116)\r\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:860)\r\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:390)\r\n\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:363)\r\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:239)\r\n\tat org.apache.spark.sql.DataFrameWriter.csv(DataFrameWriter.scala:851)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\nCaused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 136.0 failed 1 times, most recent failure: Lost task 0.0 in stage 136.0 (TID 150) (DESKTOP-GT679GD executor driver): java.io.IOException: (null) entry in command string: null chmod 0644 C:\\tmp\\spark_output\\zipcodes\\_temporary\\0\\_temporary\\attempt_2023013020081630551652960918700_0136_m_000000_150\\part-00000-f9bf5b6c-54b7-4bb2-848d-2bd49ac00cfb-c000.csv\r\n\tat org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)\r\n\tat org.apache.hadoop.util.Shell.execCommand(Shell.java:869)\r\n\tat org.apache.hadoop.util.Shell.execCommand(Shell.java:852)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:733)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:225)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:209)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.createOutputStreamWithMode(RawLocalFileSystem.java:307)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:296)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:328)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:398)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:461)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:440)\r\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:911)\r\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:892)\r\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:789)\r\n\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStream(CodecStreams.scala:81)\r\n\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStreamWriter(CodecStreams.scala:92)\r\n\tat org.apache.spark.sql.execution.datasources.csv.CsvOutputWriter.<init>(CsvOutputWriter.scala:38)\r\n\tat org.apache.spark.sql.execution.datasources.csv.CSVFileFormat$$anon$1.newInstance(CSVFileFormat.scala:84)\r\n\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.newOutputWriter(FileFormatDataWriter.scala:161)\r\n\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.<init>(FileFormatDataWriter.scala:146)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:317)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$21(FileFormatWriter.scala:256)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:136)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2672)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2608)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2607)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2607)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1182)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1182)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1182)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2860)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:952)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2228)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:245)\r\n\t... 42 more\r\nCaused by: java.io.IOException: (null) entry in command string: null chmod 0644 C:\\tmp\\spark_output\\zipcodes\\_temporary\\0\\_temporary\\attempt_2023013020081630551652960918700_0136_m_000000_150\\part-00000-f9bf5b6c-54b7-4bb2-848d-2bd49ac00cfb-c000.csv\r\n\tat org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)\r\n\tat org.apache.hadoop.util.Shell.execCommand(Shell.java:869)\r\n\tat org.apache.hadoop.util.Shell.execCommand(Shell.java:852)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:733)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:225)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:209)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.createOutputStreamWithMode(RawLocalFileSystem.java:307)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:296)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:328)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:398)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:461)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:440)\r\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:911)\r\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:892)\r\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:789)\r\n\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStream(CodecStreams.scala:81)\r\n\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStreamWriter(CodecStreams.scala:92)\r\n\tat org.apache.spark.sql.execution.datasources.csv.CsvOutputWriter.<init>(CsvOutputWriter.scala:38)\r\n\tat org.apache.spark.sql.execution.datasources.csv.CSVFileFormat$$anon$1.newInstance(CSVFileFormat.scala:84)\r\n\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.newOutputWriter(FileFormatDataWriter.scala:161)\r\n\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.<init>(FileFormatDataWriter.scala:146)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:317)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$21(FileFormatWriter.scala:256)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:136)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\t... 1 more\r\n"
     ]
    }
   ],
   "source": [
    "#df.write.option(\"header\",True) \\\n",
    "# .csv(\"/tmp/spark_output/zipcodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c7cb7b",
   "metadata": {},
   "source": [
    "# Entendendo a diferença entre as funções option() e options()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2babb40",
   "metadata": {},
   "source": [
    "# 03.3 - Importando Arquivo CSV Definindo Delimitador de Colunas e Cabeçalho\n",
    "\n",
    "## Usando Função: option()\n",
    "\n",
    "* Read a csv with delimiter and a header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "48492cb3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-----------+---------------+-----------------+--------+----------+------------------------------+----------+--------------+-----+-----+--------------+--------+-----------------+------------+------------+---------------------+---------------------+-------------------+----------------+--------------+-----------------------+-----------------------+------------------------+------------------------+---------------+----------+-------------+------------------------------+------------+-------------------+------------+-----------------------+------------+---------------+-----------------------+----------------+----------------+----------------+-----------------------+-----------------------+-------------+-------------------+-----------------------------+---------+---------+-----------------+-------------------+---------------+---------------+-----------+-----------+-----------+-------------------------+-----------------------+----------------+----------------+------------+----------------+------------------------+--------------------+----------------------------+----------------------------+--------------------------+--------------------------+--------------------------+------------------------+-------------------------+-------------------------+---------------+\n",
      "|DT_GERACAO|HH_GERACAO|ANO_ELEICAO|CD_TIPO_ELEICAO|NM_TIPO_ELEICAO  |NR_TURNO|CD_ELEICAO|DS_ELEICAO                    |DT_ELEICAO|TP_ABRANGENCIA|SG_UF|SG_UE|NM_UE         |CD_CARGO|DS_CARGO         |SQ_CANDIDATO|NR_CANDIDATO|NM_CANDIDATO         |NM_URNA_CANDIDATO    |NM_SOCIAL_CANDIDATO|NR_CPF_CANDIDATO|NM_EMAIL      |CD_SITUACAO_CANDIDATURA|DS_SITUACAO_CANDIDATURA|CD_DETALHE_SITUACAO_CAND|DS_DETALHE_SITUACAO_CAND|TP_AGREMIACAO  |NR_PARTIDO|SG_PARTIDO   |NM_PARTIDO                    |NR_FEDERACAO|NM_FEDERACAO       |SG_FEDERACAO|DS_COMPOSICAO_FEDERACAO|SQ_COLIGACAO|NM_COLIGACAO   |DS_COMPOSICAO_COLIGACAO|CD_NACIONALIDADE|DS_NACIONALIDADE|SG_UF_NASCIMENTO|CD_MUNICIPIO_NASCIMENTO|NM_MUNICIPIO_NASCIMENTO|DT_NASCIMENTO|NR_IDADE_DATA_POSSE|NR_TITULO_ELEITORAL_CANDIDATO|CD_GENERO|DS_GENERO|CD_GRAU_INSTRUCAO|DS_GRAU_INSTRUCAO  |CD_ESTADO_CIVIL|DS_ESTADO_CIVIL|CD_COR_RACA|DS_COR_RACA|CD_OCUPACAO|DS_OCUPACAO              |VR_DESPESA_MAX_CAMPANHA|CD_SIT_TOT_TURNO|DS_SIT_TOT_TURNO|ST_REELEICAO|ST_DECLARAR_BENS|NR_PROTOCOLO_CANDIDATURA|NR_PROCESSO         |CD_SITUACAO_CANDIDATO_PLEITO|DS_SITUACAO_CANDIDATO_PLEITO|CD_SITUACAO_CANDIDATO_URNA|DS_SITUACAO_CANDIDATO_URNA|ST_CANDIDATO_INSERIDO_URNA|NM_TIPO_DESTINACAO_VOTOS|CD_SITUACAO_CANDIDATO_TOT|DS_SITUACAO_CANDIDATO_TOT|ST_PREST_CONTAS|\n",
      "+----------+----------+-----------+---------------+-----------------+--------+----------+------------------------------+----------+--------------+-----+-----+--------------+--------+-----------------+------------+------------+---------------------+---------------------+-------------------+----------------+--------------+-----------------------+-----------------------+------------------------+------------------------+---------------+----------+-------------+------------------------------+------------+-------------------+------------+-----------------------+------------+---------------+-----------------------+----------------+----------------+----------------+-----------------------+-----------------------+-------------+-------------------+-----------------------------+---------+---------+-----------------+-------------------+---------------+---------------+-----------+-----------+-----------+-------------------------+-----------------------+----------------+----------------+------------+----------------+------------------------+--------------------+----------------------------+----------------------------+--------------------------+--------------------------+--------------------------+------------------------+-------------------------+-------------------------+---------------+\n",
      "|21/01/2023|18:38:33  |2022       |2              |ELEI��O ORDIN�RIA|1       |546       |Elei��es Gerais Estaduais 2022|02/10/2022|ESTADUAL      |CE   |CE   |CEAR�         |7       |DEPUTADO ESTADUAL|60001613096 |50011       |TONY BEZERRA DE SOUSA|TONY IN�CIO SHOW     |#NULO#             |12055010450     |N�O DIVULG�VEL|12                     |APTO                   |2                       |DEFERIDO                |FEDERA��O      |50        |PSOL         |PARTIDO SOCIALISMO E LIBERDADE|3           |Federa��o PSOL REDE|PSOL/REDE   |PSOL/REDE              |60001681655 |FEDERA��O      |PSOL/REDE              |1               |BRASILEIRA NATA |CE              |-3                     |FORTALEZA              |25/12/1995   |27                 |044356531260                 |2        |MASCULINO|7                |SUPERIOR INCOMPLETO|1              |SOLTEIRO(A)    |01         |BRANCA     |163        |CANTOR E COMPOSITOR      |1270629.01             |5               |SUPLENTE        |N           |N               |-1                      |06005353420226060000|2                           |DEFERIDO                    |2                         |DEFERIDO                  |SIM                       |V�lido                  |2                        |Deferido                 |S              |\n",
      "|21/01/2023|18:38:33  |2022       |2              |ELEI��O ORDIN�RIA|1       |546       |Elei��es Gerais Estaduais 2022|02/10/2022|ESTADUAL      |RJ   |RJ   |RIO DE JANEIRO|7       |DEPUTADO ESTADUAL|190001601406|77275       |S�NIA MARIA GAMA LIMA|ENFERMEIRA SONIA LIMA|#NULO#             |61260606791     |N�O DIVULG�VEL|12                     |APTO                   |2                       |DEFERIDO                |PARTIDO ISOLADO|77        |SOLIDARIEDADE|SOLIDARIEDADE                 |-1          |#NULO#             |#NULO#      |#NULO#                 |190001681112|PARTIDO ISOLADO|SOLIDARIEDADE          |1               |BRASILEIRA NATA |RJ              |-3                     |RIO DE JANEIRO         |07/12/1960   |62                 |015784480370                 |4        |FEMININO |8                |SUPERIOR COMPLETO  |9              |DIVORCIADO(A)  |01         |BRANCA     |297        |SERVIDOR P�BLICO ESTADUAL|1270629.01             |5               |SUPLENTE        |N           |S               |-1                      |06008292620226190000|2                           |DEFERIDO                    |2                         |DEFERIDO                  |SIM                       |V�lido                  |2                        |Deferido                 |S              |\n",
      "+----------+----------+-----------+---------------+-----------------+--------+----------+------------------------------+----------+--------------+-----+-----+--------------+--------+-----------------+------------+------------+---------------------+---------------------+-------------------+----------------+--------------+-----------------------+-----------------------+------------------------+------------------------+---------------+----------+-------------+------------------------------+------------+-------------------+------------+-----------------------+------------+---------------+-----------------------+----------------+----------------+----------------+-----------------------+-----------------------+-------------+-------------------+-----------------------------+---------+---------+-----------------+-------------------+---------------+---------------+-----------+-----------+-----------+-------------------------+-----------------------+----------------+----------------+------------+----------------+------------------------+--------------------+----------------------------+----------------------------+--------------------------+--------------------------+--------------------------+------------------------+-------------------------+-------------------------+---------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "arquivo = '../ProjetoSparkKB/Dados/Candidato/consulta_cand_2022_BRASIL.csv'\n",
    "\n",
    "df = spark.read.option('delimiter',';') \\\n",
    "                .option('header','True') \\\n",
    "                .csv(arquivo)\n",
    "\n",
    "#df.select('DT_GERACAO').show()\n",
    "\n",
    "df.show(2,truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d9e2d7",
   "metadata": {},
   "source": [
    "## Usando Função: options()\n",
    "\n",
    "* You can also use options() to use multiple options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "525e45fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-----------+---------------+-----------------+--------+----------+------------------------------+----------+--------------+-----+-----+--------------+--------+-----------------+------------+------------+---------------------+---------------------+-------------------+----------------+--------------+-----------------------+-----------------------+------------------------+------------------------+---------------+----------+-------------+------------------------------+------------+-------------------+------------+-----------------------+------------+---------------+-----------------------+----------------+----------------+----------------+-----------------------+-----------------------+-------------+-------------------+-----------------------------+---------+---------+-----------------+-------------------+---------------+---------------+-----------+-----------+-----------+-------------------------+-----------------------+----------------+----------------+------------+----------------+------------------------+--------------------+----------------------------+----------------------------+--------------------------+--------------------------+--------------------------+------------------------+-------------------------+-------------------------+---------------+\n",
      "|DT_GERACAO|HH_GERACAO|ANO_ELEICAO|CD_TIPO_ELEICAO|NM_TIPO_ELEICAO  |NR_TURNO|CD_ELEICAO|DS_ELEICAO                    |DT_ELEICAO|TP_ABRANGENCIA|SG_UF|SG_UE|NM_UE         |CD_CARGO|DS_CARGO         |SQ_CANDIDATO|NR_CANDIDATO|NM_CANDIDATO         |NM_URNA_CANDIDATO    |NM_SOCIAL_CANDIDATO|NR_CPF_CANDIDATO|NM_EMAIL      |CD_SITUACAO_CANDIDATURA|DS_SITUACAO_CANDIDATURA|CD_DETALHE_SITUACAO_CAND|DS_DETALHE_SITUACAO_CAND|TP_AGREMIACAO  |NR_PARTIDO|SG_PARTIDO   |NM_PARTIDO                    |NR_FEDERACAO|NM_FEDERACAO       |SG_FEDERACAO|DS_COMPOSICAO_FEDERACAO|SQ_COLIGACAO|NM_COLIGACAO   |DS_COMPOSICAO_COLIGACAO|CD_NACIONALIDADE|DS_NACIONALIDADE|SG_UF_NASCIMENTO|CD_MUNICIPIO_NASCIMENTO|NM_MUNICIPIO_NASCIMENTO|DT_NASCIMENTO|NR_IDADE_DATA_POSSE|NR_TITULO_ELEITORAL_CANDIDATO|CD_GENERO|DS_GENERO|CD_GRAU_INSTRUCAO|DS_GRAU_INSTRUCAO  |CD_ESTADO_CIVIL|DS_ESTADO_CIVIL|CD_COR_RACA|DS_COR_RACA|CD_OCUPACAO|DS_OCUPACAO              |VR_DESPESA_MAX_CAMPANHA|CD_SIT_TOT_TURNO|DS_SIT_TOT_TURNO|ST_REELEICAO|ST_DECLARAR_BENS|NR_PROTOCOLO_CANDIDATURA|NR_PROCESSO         |CD_SITUACAO_CANDIDATO_PLEITO|DS_SITUACAO_CANDIDATO_PLEITO|CD_SITUACAO_CANDIDATO_URNA|DS_SITUACAO_CANDIDATO_URNA|ST_CANDIDATO_INSERIDO_URNA|NM_TIPO_DESTINACAO_VOTOS|CD_SITUACAO_CANDIDATO_TOT|DS_SITUACAO_CANDIDATO_TOT|ST_PREST_CONTAS|\n",
      "+----------+----------+-----------+---------------+-----------------+--------+----------+------------------------------+----------+--------------+-----+-----+--------------+--------+-----------------+------------+------------+---------------------+---------------------+-------------------+----------------+--------------+-----------------------+-----------------------+------------------------+------------------------+---------------+----------+-------------+------------------------------+------------+-------------------+------------+-----------------------+------------+---------------+-----------------------+----------------+----------------+----------------+-----------------------+-----------------------+-------------+-------------------+-----------------------------+---------+---------+-----------------+-------------------+---------------+---------------+-----------+-----------+-----------+-------------------------+-----------------------+----------------+----------------+------------+----------------+------------------------+--------------------+----------------------------+----------------------------+--------------------------+--------------------------+--------------------------+------------------------+-------------------------+-------------------------+---------------+\n",
      "|21/01/2023|18:38:33  |2022       |2              |ELEI��O ORDIN�RIA|1       |546       |Elei��es Gerais Estaduais 2022|02/10/2022|ESTADUAL      |CE   |CE   |CEAR�         |7       |DEPUTADO ESTADUAL|60001613096 |50011       |TONY BEZERRA DE SOUSA|TONY IN�CIO SHOW     |#NULO#             |12055010450     |N�O DIVULG�VEL|12                     |APTO                   |2                       |DEFERIDO                |FEDERA��O      |50        |PSOL         |PARTIDO SOCIALISMO E LIBERDADE|3           |Federa��o PSOL REDE|PSOL/REDE   |PSOL/REDE              |60001681655 |FEDERA��O      |PSOL/REDE              |1               |BRASILEIRA NATA |CE              |-3                     |FORTALEZA              |25/12/1995   |27                 |044356531260                 |2        |MASCULINO|7                |SUPERIOR INCOMPLETO|1              |SOLTEIRO(A)    |01         |BRANCA     |163        |CANTOR E COMPOSITOR      |1270629.01             |5               |SUPLENTE        |N           |N               |-1                      |06005353420226060000|2                           |DEFERIDO                    |2                         |DEFERIDO                  |SIM                       |V�lido                  |2                        |Deferido                 |S              |\n",
      "|21/01/2023|18:38:33  |2022       |2              |ELEI��O ORDIN�RIA|1       |546       |Elei��es Gerais Estaduais 2022|02/10/2022|ESTADUAL      |RJ   |RJ   |RIO DE JANEIRO|7       |DEPUTADO ESTADUAL|190001601406|77275       |S�NIA MARIA GAMA LIMA|ENFERMEIRA SONIA LIMA|#NULO#             |61260606791     |N�O DIVULG�VEL|12                     |APTO                   |2                       |DEFERIDO                |PARTIDO ISOLADO|77        |SOLIDARIEDADE|SOLIDARIEDADE                 |-1          |#NULO#             |#NULO#      |#NULO#                 |190001681112|PARTIDO ISOLADO|SOLIDARIEDADE          |1               |BRASILEIRA NATA |RJ              |-3                     |RIO DE JANEIRO         |07/12/1960   |62                 |015784480370                 |4        |FEMININO |8                |SUPERIOR COMPLETO  |9              |DIVORCIADO(A)  |01         |BRANCA     |297        |SERVIDOR P�BLICO ESTADUAL|1270629.01             |5               |SUPLENTE        |N           |S               |-1                      |06008292620226190000|2                           |DEFERIDO                    |2                         |DEFERIDO                  |SIM                       |V�lido                  |2                        |Deferido                 |S              |\n",
      "+----------+----------+-----------+---------------+-----------------+--------+----------+------------------------------+----------+--------------+-----+-----+--------------+--------+-----------------+------------+------------+---------------------+---------------------+-------------------+----------------+--------------+-----------------------+-----------------------+------------------------+------------------------+---------------+----------+-------------+------------------------------+------------+-------------------+------------+-----------------------+------------+---------------+-----------------------+----------------+----------------+----------------+-----------------------+-----------------------+-------------+-------------------+-----------------------------+---------+---------+-----------------+-------------------+---------------+---------------+-----------+-----------+-----------+-------------------------+-----------------------+----------------+----------------+------------+----------------+------------------------+--------------------+----------------------------+----------------------------+--------------------------+--------------------------+--------------------------+------------------------+-------------------------+-------------------------+---------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "arquivo = '../ProjetoSparkKB/Dados/Candidato/consulta_cand_2022_BRASIL.csv'\n",
    "\n",
    "df = spark.read.options(delimiter=';'\n",
    "                        , header='True') \\\n",
    "                        .csv(arquivo)\n",
    "\n",
    "#df.select('DT_GERACAO').show()\n",
    "\n",
    "df.show(2,truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf43e8b3",
   "metadata": {},
   "source": [
    "# 03.4 - Importando TODOS os Arquivos CSV de um Diretório\n",
    "\n",
    "## Usando spark.read.csv()\n",
    "\n",
    "* Read all files in a folder, please make sure only CSV files should present in the folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f8c08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "folderPath = \"../ProjetoSparkKB/Dados/Candidato/\"\n",
    "df5 = spark.read.csv(folderPath,sep=';')\n",
    "df5.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69cd341",
   "metadata": {},
   "source": [
    "## Usando spark.read.format()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07c5f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivo = '../ProjetoSparkKB/Dados/Candidato/consulta_cand_2022_BRASIL.csv'\n",
    "\n",
    "dfExemplo2 = spark.read.format(\"csv\").load(arquivo)\n",
    "    \n",
    "dfExemplo2.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa22e35",
   "metadata": {},
   "source": [
    "# 03.5 - Importando Arquivo CSV Definindo inferSchema\n",
    "\n",
    "## Entendendo o parâmetro inferSchema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e66691",
   "metadata": {},
   "source": [
    "## Parâmetro inferSchema FALSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f47db82",
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivo = '../ProjetoSparkKB/Dados/Candidato/consulta_cand_2022_BRASIL.csv'\n",
    "\n",
    "dfExemplo3 = spark.read.option(\"inferSchema\",False) \\\n",
    "                .option(\"delimiter\",\";\") \\\n",
    "                .option(\"header\",True) \\\n",
    "                .csv(arquivo)\n",
    "\n",
    "dfExemplo3.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669295de",
   "metadata": {},
   "source": [
    "## Parâmetro inferSchema TRUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "fe817b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DT_GERACAO: string (nullable = true)\n",
      " |-- HH_GERACAO: timestamp (nullable = true)\n",
      " |-- ANO_ELEICAO: integer (nullable = true)\n",
      " |-- CD_TIPO_ELEICAO: integer (nullable = true)\n",
      " |-- NM_TIPO_ELEICAO: string (nullable = true)\n",
      " |-- NR_TURNO: integer (nullable = true)\n",
      " |-- CD_ELEICAO: integer (nullable = true)\n",
      " |-- DS_ELEICAO: string (nullable = true)\n",
      " |-- DT_ELEICAO: string (nullable = true)\n",
      " |-- TP_ABRANGENCIA: string (nullable = true)\n",
      " |-- SG_UF: string (nullable = true)\n",
      " |-- SG_UE: string (nullable = true)\n",
      " |-- NM_UE: string (nullable = true)\n",
      " |-- CD_CARGO: integer (nullable = true)\n",
      " |-- DS_CARGO: string (nullable = true)\n",
      " |-- SQ_CANDIDATO: long (nullable = true)\n",
      " |-- NR_CANDIDATO: integer (nullable = true)\n",
      " |-- NM_CANDIDATO: string (nullable = true)\n",
      " |-- NM_URNA_CANDIDATO: string (nullable = true)\n",
      " |-- NM_SOCIAL_CANDIDATO: string (nullable = true)\n",
      " |-- NR_CPF_CANDIDATO: long (nullable = true)\n",
      " |-- NM_EMAIL: string (nullable = true)\n",
      " |-- CD_SITUACAO_CANDIDATURA: integer (nullable = true)\n",
      " |-- DS_SITUACAO_CANDIDATURA: string (nullable = true)\n",
      " |-- CD_DETALHE_SITUACAO_CAND: integer (nullable = true)\n",
      " |-- DS_DETALHE_SITUACAO_CAND: string (nullable = true)\n",
      " |-- TP_AGREMIACAO: string (nullable = true)\n",
      " |-- NR_PARTIDO: integer (nullable = true)\n",
      " |-- SG_PARTIDO: string (nullable = true)\n",
      " |-- NM_PARTIDO: string (nullable = true)\n",
      " |-- NR_FEDERACAO: integer (nullable = true)\n",
      " |-- NM_FEDERACAO: string (nullable = true)\n",
      " |-- SG_FEDERACAO: string (nullable = true)\n",
      " |-- DS_COMPOSICAO_FEDERACAO: string (nullable = true)\n",
      " |-- SQ_COLIGACAO: long (nullable = true)\n",
      " |-- NM_COLIGACAO: string (nullable = true)\n",
      " |-- DS_COMPOSICAO_COLIGACAO: string (nullable = true)\n",
      " |-- CD_NACIONALIDADE: integer (nullable = true)\n",
      " |-- DS_NACIONALIDADE: string (nullable = true)\n",
      " |-- SG_UF_NASCIMENTO: string (nullable = true)\n",
      " |-- CD_MUNICIPIO_NASCIMENTO: integer (nullable = true)\n",
      " |-- NM_MUNICIPIO_NASCIMENTO: string (nullable = true)\n",
      " |-- DT_NASCIMENTO: string (nullable = true)\n",
      " |-- NR_IDADE_DATA_POSSE: integer (nullable = true)\n",
      " |-- NR_TITULO_ELEITORAL_CANDIDATO: long (nullable = true)\n",
      " |-- CD_GENERO: integer (nullable = true)\n",
      " |-- DS_GENERO: string (nullable = true)\n",
      " |-- CD_GRAU_INSTRUCAO: integer (nullable = true)\n",
      " |-- DS_GRAU_INSTRUCAO: string (nullable = true)\n",
      " |-- CD_ESTADO_CIVIL: integer (nullable = true)\n",
      " |-- DS_ESTADO_CIVIL: string (nullable = true)\n",
      " |-- CD_COR_RACA: integer (nullable = true)\n",
      " |-- DS_COR_RACA: string (nullable = true)\n",
      " |-- CD_OCUPACAO: integer (nullable = true)\n",
      " |-- DS_OCUPACAO: string (nullable = true)\n",
      " |-- VR_DESPESA_MAX_CAMPANHA: double (nullable = true)\n",
      " |-- CD_SIT_TOT_TURNO: integer (nullable = true)\n",
      " |-- DS_SIT_TOT_TURNO: string (nullable = true)\n",
      " |-- ST_REELEICAO: string (nullable = true)\n",
      " |-- ST_DECLARAR_BENS: string (nullable = true)\n",
      " |-- NR_PROTOCOLO_CANDIDATURA: integer (nullable = true)\n",
      " |-- NR_PROCESSO: long (nullable = true)\n",
      " |-- CD_SITUACAO_CANDIDATO_PLEITO: integer (nullable = true)\n",
      " |-- DS_SITUACAO_CANDIDATO_PLEITO: string (nullable = true)\n",
      " |-- CD_SITUACAO_CANDIDATO_URNA: integer (nullable = true)\n",
      " |-- DS_SITUACAO_CANDIDATO_URNA: string (nullable = true)\n",
      " |-- ST_CANDIDATO_INSERIDO_URNA: string (nullable = true)\n",
      " |-- NM_TIPO_DESTINACAO_VOTOS: string (nullable = true)\n",
      " |-- CD_SITUACAO_CANDIDATO_TOT: integer (nullable = true)\n",
      " |-- DS_SITUACAO_CANDIDATO_TOT: string (nullable = true)\n",
      " |-- ST_PREST_CONTAS: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "arquivo = '../ProjetoSparkKB/Dados/Candidato/consulta_cand_2022_BRASIL.csv'\n",
    "\n",
    "dfExemplo04 = spark.read.options(header='True'\n",
    "                                 , inferSchema='True'\n",
    "                                 , delimiter=';') \\\n",
    "                                 .csv(arquivo)\n",
    "\n",
    "dfExemplo04.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cf3e69",
   "metadata": {},
   "source": [
    "# 03.6 - Importando Arquivo CSV Definindo encoding\n",
    "\n",
    "## Entendendo o parâmetro encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "d9fa56d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+-----------+---------------+-----------------+--------+----------+--------------------+----------+--------------+-----+-----+-----------------+--------+-----------------+------------+------------+--------------------+--------------------+-------------------+----------------+--------------+-----------------------+-----------------------+------------------------+------------------------+---------------+----------+-------------+--------------------+------------+--------------------+--------------+-----------------------+------------+---------------+-----------------------+----------------+----------------+----------------+-----------------------+-----------------------+-------------+-------------------+-----------------------------+---------+---------+-----------------+--------------------+---------------+---------------+-----------+-----------+-----------+--------------------+-----------------------+----------------+----------------+------------+----------------+------------------------+-------------------+----------------------------+----------------------------+--------------------------+--------------------------+--------------------------+------------------------+-------------------------+-------------------------+---------------+\n",
      "|DT_GERACAO|         HH_GERACAO|ANO_ELEICAO|CD_TIPO_ELEICAO|  NM_TIPO_ELEICAO|NR_TURNO|CD_ELEICAO|          DS_ELEICAO|DT_ELEICAO|TP_ABRANGENCIA|SG_UF|SG_UE|            NM_UE|CD_CARGO|         DS_CARGO|SQ_CANDIDATO|NR_CANDIDATO|        NM_CANDIDATO|   NM_URNA_CANDIDATO|NM_SOCIAL_CANDIDATO|NR_CPF_CANDIDATO|      NM_EMAIL|CD_SITUACAO_CANDIDATURA|DS_SITUACAO_CANDIDATURA|CD_DETALHE_SITUACAO_CAND|DS_DETALHE_SITUACAO_CAND|  TP_AGREMIACAO|NR_PARTIDO|   SG_PARTIDO|          NM_PARTIDO|NR_FEDERACAO|        NM_FEDERACAO|  SG_FEDERACAO|DS_COMPOSICAO_FEDERACAO|SQ_COLIGACAO|   NM_COLIGACAO|DS_COMPOSICAO_COLIGACAO|CD_NACIONALIDADE|DS_NACIONALIDADE|SG_UF_NASCIMENTO|CD_MUNICIPIO_NASCIMENTO|NM_MUNICIPIO_NASCIMENTO|DT_NASCIMENTO|NR_IDADE_DATA_POSSE|NR_TITULO_ELEITORAL_CANDIDATO|CD_GENERO|DS_GENERO|CD_GRAU_INSTRUCAO|   DS_GRAU_INSTRUCAO|CD_ESTADO_CIVIL|DS_ESTADO_CIVIL|CD_COR_RACA|DS_COR_RACA|CD_OCUPACAO|         DS_OCUPACAO|VR_DESPESA_MAX_CAMPANHA|CD_SIT_TOT_TURNO|DS_SIT_TOT_TURNO|ST_REELEICAO|ST_DECLARAR_BENS|NR_PROTOCOLO_CANDIDATURA|        NR_PROCESSO|CD_SITUACAO_CANDIDATO_PLEITO|DS_SITUACAO_CANDIDATO_PLEITO|CD_SITUACAO_CANDIDATO_URNA|DS_SITUACAO_CANDIDATO_URNA|ST_CANDIDATO_INSERIDO_URNA|NM_TIPO_DESTINACAO_VOTOS|CD_SITUACAO_CANDIDATO_TOT|DS_SITUACAO_CANDIDATO_TOT|ST_PREST_CONTAS|\n",
      "+----------+-------------------+-----------+---------------+-----------------+--------+----------+--------------------+----------+--------------+-----+-----+-----------------+--------+-----------------+------------+------------+--------------------+--------------------+-------------------+----------------+--------------+-----------------------+-----------------------+------------------------+------------------------+---------------+----------+-------------+--------------------+------------+--------------------+--------------+-----------------------+------------+---------------+-----------------------+----------------+----------------+----------------+-----------------------+-----------------------+-------------+-------------------+-----------------------------+---------+---------+-----------------+--------------------+---------------+---------------+-----------+-----------+-----------+--------------------+-----------------------+----------------+----------------+------------+----------------+------------------------+-------------------+----------------------------+----------------------------+--------------------------+--------------------------+--------------------------+------------------------+-------------------------+-------------------------+---------------+\n",
      "|21/01/2023|2023-01-30 18:38:33|       2022|              2|ELEIÇÃO ORDINÁRIA|       1|       546|Eleições Gerais E...|02/10/2022|      ESTADUAL|   CE|   CE|            CEARÁ|       7|DEPUTADO ESTADUAL| 60001613096|       50011|TONY BEZERRA DE S...|    TONY INÁCIO SHOW|             #NULO#|     12055010450|NÃO DIVULGÁVEL|                     12|                   APTO|                       2|                DEFERIDO|      FEDERAÇÃO|        50|         PSOL|PARTIDO SOCIALISM...|           3| Federação PSOL REDE|     PSOL/REDE|              PSOL/REDE| 60001681655|      FEDERAÇÃO|              PSOL/REDE|               1| BRASILEIRA NATA|              CE|                     -3|              FORTALEZA|   25/12/1995|                 27|                  44356531260|        2|MASCULINO|                7| SUPERIOR INCOMPLETO|              1|    SOLTEIRO(A)|          1|     BRANCA|        163| CANTOR E COMPOSITOR|             1270629.01|               5|        SUPLENTE|           N|               N|                      -1|6005353420226060000|                           2|                    DEFERIDO|                         2|                  DEFERIDO|                       SIM|                  Válido|                        2|                 Deferido|              S|\n",
      "|21/01/2023|2023-01-30 18:38:33|       2022|              2|ELEIÇÃO ORDINÁRIA|       1|       546|Eleições Gerais E...|02/10/2022|      ESTADUAL|   RJ|   RJ|   RIO DE JANEIRO|       7|DEPUTADO ESTADUAL|190001601406|       77275|SÔNIA MARIA GAMA ...|ENFERMEIRA SONIA ...|             #NULO#|     61260606791|NÃO DIVULGÁVEL|                     12|                   APTO|                       2|                DEFERIDO|PARTIDO ISOLADO|        77|SOLIDARIEDADE|       SOLIDARIEDADE|          -1|              #NULO#|        #NULO#|                 #NULO#|190001681112|PARTIDO ISOLADO|          SOLIDARIEDADE|               1| BRASILEIRA NATA|              RJ|                     -3|         RIO DE JANEIRO|   07/12/1960|                 62|                  15784480370|        4| FEMININO|                8|   SUPERIOR COMPLETO|              9|  DIVORCIADO(A)|          1|     BRANCA|        297|SERVIDOR PÚBLICO ...|             1270629.01|               5|        SUPLENTE|           N|               S|                      -1|6008292620226190000|                           2|                    DEFERIDO|                         2|                  DEFERIDO|                       SIM|                  Válido|                        2|                 Deferido|              S|\n",
      "|21/01/2023|2023-01-30 18:38:33|       2022|              2|ELEIÇÃO ORDINÁRIA|       1|       546|Eleições Gerais E...|02/10/2022|      ESTADUAL|   RS|   RS|RIO GRANDE DO SUL|       7|DEPUTADO ESTADUAL|210001621288|       12555|GUSTAVO TANGER JA...|       TANGER JARDIM|             #NULO#|     74721399049|NÃO DIVULGÁVEL|                     12|                   APTO|                       2|                DEFERIDO|PARTIDO ISOLADO|        12|          PDT|PARTIDO DEMOCRÁTI...|          -1|              #NULO#|        #NULO#|                 #NULO#|210001682258|PARTIDO ISOLADO|                    PDT|               1| BRASILEIRA NATA|              RS|                     -3|                PELOTAS|   15/06/1975|                 47|                  61922100426|        2|MASCULINO|                8|   SUPERIOR COMPLETO|              3|      CASADO(A)|          1|     BRANCA|        131|            ADVOGADO|             1270629.01|               5|        SUPLENTE|           N|               S|                      -1|6013233120226210000|                           2|                    DEFERIDO|                         2|                  DEFERIDO|                       SIM|                  Válido|                        2|                 Deferido|              S|\n",
      "|21/01/2023|2023-01-30 18:38:33|       2022|              2|ELEIÇÃO ORDINÁRIA|       1|       546|Eleições Gerais E...|02/10/2022|      ESTADUAL|   SP|   SP|        SÃO PAULO|       6| DEPUTADO FEDERAL|250001604811|        1415|      VALDEMAR SILVA|  VAVA DO TRANSPORTE|             #NULO#|      6445151809|NÃO DIVULGÁVEL|                     12|                   APTO|                       2|                DEFERIDO|PARTIDO ISOLADO|        14|          PTB|PARTIDO TRABALHIS...|          -1|              #NULO#|        #NULO#|                 #NULO#|250001681260|PARTIDO ISOLADO|                    PTB|               1| BRASILEIRA NATA|              SP|                     -3|            SANTO ANDRÉ|   20/05/1964|                 58|                 153903270191|        2|MASCULINO|                8|   SUPERIOR COMPLETO|              3|      CASADO(A)|          1|     BRANCA|        923|APOSENTADO (EXCET...|             3176572.53|               4|      NÃO ELEITO|           N|               S|                      -1|6007124020226260000|                           2|                    DEFERIDO|                         2|                  DEFERIDO|                       SIM|                  Válido|                        2|                 Deferido|              S|\n",
      "|21/01/2023|2023-01-30 18:38:33|       2022|              2|ELEIÇÃO ORDINÁRIA|       1|       546|Eleições Gerais E...|02/10/2022|      ESTADUAL|   AM|   AM|         AMAZONAS|       6| DEPUTADO FEDERAL| 40001618450|        4440|LEDA MARIA MAIA X...|           LEDA MAIA|             #NULO#|     94071586249|NÃO DIVULGÁVEL|                     12|                   APTO|                       2|                DEFERIDO|PARTIDO ISOLADO|        44|        UNIÃO|        UNIÃO BRASIL|          -1|              #NULO#|        #NULO#|                 #NULO#| 40001682111|PARTIDO ISOLADO|                  UNIÃO|               1| BRASILEIRA NATA|              AM|                     -3|                 MANAUS|   19/02/1991|                 31|                  34547062216|        4| FEMININO|                8|   SUPERIOR COMPLETO|              9|  DIVORCIADO(A)|          3|      PARDA|        172|        PUBLICITÁRIO|             3176572.53|               5|        SUPLENTE|           N|               S|                      -1|6004613420226040000|                           2|                    DEFERIDO|                         2|                  DEFERIDO|                       SIM|                  Válido|                        2|                 Deferido|              S|\n",
      "|21/01/2023|2023-01-30 18:38:33|       2022|              2|ELEIÇÃO ORDINÁRIA|       1|       546|Eleições Gerais E...|02/10/2022|      ESTADUAL|   AL|   AL|          ALAGOAS|       6| DEPUTADO FEDERAL| 20001652299|        5588|EDUARDO ÍTALO BAS...|        ÍTALO BASTOS|             #NULO#|      3341153454|NÃO DIVULGÁVEL|                     12|                   APTO|                       2|                DEFERIDO|PARTIDO ISOLADO|        55|          PSD|PARTIDO SOCIAL DE...|          -1|              #NULO#|        #NULO#|                 #NULO#| 20001683386|PARTIDO ISOLADO|                    PSD|               1| BRASILEIRA NATA|              AL|                     -3|                 MACEIÓ|   02/09/1980|                 42|                  25735071716|        2|MASCULINO|                8|   SUPERIOR COMPLETO|              3|      CASADO(A)|          1|     BRANCA|        233|    POLICIAL MILITAR|             3176572.53|               4|      NÃO ELEITO|           N|               S|                      -1|6005804920226020000|                           2|                    DEFERIDO|                         2|                  DEFERIDO|                       SIM|                  Válido|                        2|                 Deferido|              S|\n",
      "|21/01/2023|2023-01-30 18:38:33|       2022|              2|ELEIÇÃO ORDINÁRIA|       1|       546|Eleições Gerais E...|02/10/2022|      ESTADUAL|   MG|   MG|     MINAS GERAIS|       6| DEPUTADO FEDERAL|130001596012|        5144|CARCILEI SOARES M...|     CARCILEI SOARES|             #NULO#|      2579141618|NÃO DIVULGÁVEL|                     12|                   APTO|                       2|                DEFERIDO|PARTIDO ISOLADO|        51|     PATRIOTA|            PATRIOTA|          -1|              #NULO#|        #NULO#|                 #NULO#|130001680879|PARTIDO ISOLADO|               PATRIOTA|               1| BRASILEIRA NATA|              MG|                     -3|                ALFENAS|   10/02/1974|                 48|                 101539230213|        2|MASCULINO|                6|ENSINO MÉDIO COMP...|              3|      CASADO(A)|          3|      PARDA|        257|          EMPRESÁRIO|             3176572.53|               5|        SUPLENTE|           N|               S|                      -1|6005215520226130000|                           2|                    DEFERIDO|                         2|                  DEFERIDO|                       SIM|                  Válido|                        2|                 Deferido|              S|\n",
      "|21/01/2023|2023-01-30 18:38:33|       2022|              2|ELEIÇÃO ORDINÁRIA|       1|       546|Eleições Gerais E...|02/10/2022|      ESTADUAL|   RJ|   RJ|   RIO DE JANEIRO|       7|DEPUTADO ESTADUAL|190001639169|       40666|MARCELO DE OLIVEI...|PAI MARCELO DE OX...|             #NULO#|      3002601721|NÃO DIVULGÁVEL|                     12|                   APTO|                       2|                DEFERIDO|PARTIDO ISOLADO|        40|          PSB|PARTIDO SOCIALIST...|          -1|              #NULO#|        #NULO#|                 #NULO#|190001682808|PARTIDO ISOLADO|                    PSB|               1| BRASILEIRA NATA|              RJ|                     -3|         RIO DE JANEIRO|   12/02/1972|                 50|                  86030660337|        2|MASCULINO|                6|ENSINO MÉDIO COMP...|              1|    SOLTEIRO(A)|          3|      PARDA|        169|         COMERCIANTE|             1270629.01|               5|        SUPLENTE|           N|               S|                      -1|6024558020226190000|                           2|                    DEFERIDO|                         2|                  DEFERIDO|                       SIM|                  Válido|                        2|                 Deferido|              S|\n",
      "|21/01/2023|2023-01-30 18:38:33|       2022|              2|ELEIÇÃO ORDINÁRIA|       1|       546|Eleições Gerais E...|02/10/2022|      ESTADUAL|   PR|   PR|           PARANÁ|       6| DEPUTADO FEDERAL|160001614489|        1455|     MAGNO ZANELLATO|            DR MAGNO|             #NULO#|     87463490904|NÃO DIVULGÁVEL|                     12|                   APTO|                       2|                DEFERIDO|PARTIDO ISOLADO|        14|          PTB|PARTIDO TRABALHIS...|          -1|              #NULO#|        #NULO#|                 #NULO#|160001681735|PARTIDO ISOLADO|                    PTB|               1| BRASILEIRA NATA|              PR|                     -3|               CURITIBA|   13/11/1971|                 51|                  49527500698|        2|MASCULINO|                8|   SUPERIOR COMPLETO|              3|      CASADO(A)|          1|     BRANCA|        111|              MÉDICO|             3176572.53|               4|      NÃO ELEITO|           N|               S|                      -1|6006828120226160000|                           2|                    DEFERIDO|                         2|                  DEFERIDO|                       SIM|                  Válido|                        2|                 Deferido|              S|\n",
      "|21/01/2023|2023-01-30 18:38:33|       2022|              2|ELEIÇÃO ORDINÁRIA|       1|       546|Eleições Gerais E...|02/10/2022|      ESTADUAL|   ES|   ES|   ESPÍRITO SANTO|       7|DEPUTADO ESTADUAL| 80001602769|       45888|VANETE CARIRI DOS...|       VANETE CARIRI|             #NULO#|      8974917777|NÃO DIVULGÁVEL|                     12|                   APTO|                       2|                DEFERIDO|      FEDERAÇÃO|        45|         PSDB|PARTIDO DA SOCIAL...|           1|Federação PSDB Ci...|PSDB/CIDADANIA|         PSDB/CIDADANIA| 80001681183|      FEDERAÇÃO|         PSDB/CIDADANIA|               1| BRASILEIRA NATA|              ES|                     -3|                VITÓRIA|   28/04/1975|                 47|                  70232560531|        4| FEMININO|                3|ENSINO FUNDAMENTA...|              3|      CASADO(A)|          2|      PRETA|        999|              OUTROS|             1270629.01|               5|        SUPLENTE|           N|               S|                      -1|6004968020226080000|                           2|                    DEFERIDO|                         2|                  DEFERIDO|                       SIM|                  Válido|                        2|                 Deferido|              S|\n",
      "|21/01/2023|2023-01-30 18:38:33|       2022|              2|ELEIÇÃO ORDINÁRIA|       1|       546|Eleições Gerais E...|02/10/2022|      ESTADUAL|   PR|   PR|           PARANÁ|       7|DEPUTADO ESTADUAL|160001716096|       28777|RONNIE CARLOS ALB...|       RONNIE CASTRO|             #NULO#|      6839985954|NÃO DIVULGÁVEL|                     12|                   APTO|                       2|                DEFERIDO|PARTIDO ISOLADO|        28|         PRTB|PARTIDO RENOVADOR...|          -1|              #NULO#|        #NULO#|                 #NULO#|160001685183|PARTIDO ISOLADO|                   PRTB|               1| BRASILEIRA NATA|              PR|                     -3|   SÃO JOSÉ DOS PINHAIS|   11/10/1989|                 33|                  96788220647|        2|MASCULINO|                3|ENSINO FUNDAMENTA...|              1|    SOLTEIRO(A)|          1|     BRANCA|        999|              OUTROS|             1270629.01|               4|      NÃO ELEITO|           N|               S|                      -1|6016268320226160000|                           2|                    DEFERIDO|                         2|                  DEFERIDO|                       SIM|                  Válido|                        2|                 Deferido|              S|\n",
      "|21/01/2023|2023-01-30 18:38:33|       2022|              2|ELEIÇÃO ORDINÁRIA|       1|       546|Eleições Gerais E...|02/10/2022|      ESTADUAL|   PA|   PA|             PARÁ|       7|DEPUTADO ESTADUAL|140001611695|       44123|ELIEL PEREIRA FAU...|      ELIEL FAUSTINO|             #NULO#|     18414303234|NÃO DIVULGÁVEL|                     12|                   APTO|                       2|                DEFERIDO|PARTIDO ISOLADO|        44|        UNIÃO|        UNIÃO BRASIL|          -1|              #NULO#|        #NULO#|                 #NULO#|140001681586|PARTIDO ISOLADO|                  UNIÃO|               1| BRASILEIRA NATA|              PA|                     -3|                  BELÉM|   11/03/1965|                 57|                  37324181376|        2|MASCULINO|                8|   SUPERIOR COMPLETO|              3|      CASADO(A)|          1|     BRANCA|        101|          ENGENHEIRO|             1270629.01|               5|        SUPLENTE|           S|               S|                      -1|6005594020226140000|                           2|                    DEFERIDO|                         2|                  DEFERIDO|                       SIM|                  Válido|                        2|                 Deferido|              S|\n",
      "|21/01/2023|2023-01-30 18:38:33|       2022|              2|ELEIÇÃO ORDINÁRIA|       1|       546|Eleições Gerais E...|02/10/2022|      ESTADUAL|   RJ|   RJ|   RIO DE JANEIRO|       6| DEPUTADO FEDERAL|190001645421|        4050|MARCOS UCHÔA CAVA...|        MARCOS UCHÔA|             #NULO#|     53251490753|NÃO DIVULGÁVEL|                     12|                   APTO|                       2|                DEFERIDO|PARTIDO ISOLADO|        40|          PSB|PARTIDO SOCIALIST...|          -1|              #NULO#|        #NULO#|                 #NULO#|190001683153|PARTIDO ISOLADO|                    PSB|               1| BRASILEIRA NATA|              RJ|                     -3|         RIO DE JANEIRO|   01/07/1958|                 64|                   2323710302|        2|MASCULINO|                8|   SUPERIOR COMPLETO|              3|      CASADO(A)|          1|     BRANCA|        171|JORNALISTA E REDATOR|             3176572.53|               5|        SUPLENTE|           N|               S|                      -1|6027216720226190000|                           2|                    DEFERIDO|                         2|                  DEFERIDO|                       SIM|                  Válido|                        2|                 Deferido|              S|\n",
      "|21/01/2023|2023-01-30 18:38:33|       2022|              2|ELEIÇÃO ORDINÁRIA|       1|       546|Eleições Gerais E...|02/10/2022|      ESTADUAL|   ES|   ES|   ESPÍRITO SANTO|       7|DEPUTADO ESTADUAL| 80001724744|       90900|IDELFONSO SANTOS ...|IDELFONSO DA VITORIA|             #NULO#|       522875726|NÃO DIVULGÁVEL|                     12|                   APTO|                       2|                DEFERIDO|PARTIDO ISOLADO|        90|         PROS|PARTIDO REPUBLICA...|          -1|              #NULO#|        #NULO#|                 #NULO#| 80001685520|PARTIDO ISOLADO|                   PROS|               1| BRASILEIRA NATA|              ES|                     -3|                VITÓRIA|   29/10/1970|                 52|                  13538171490|        2|MASCULINO|                8|   SUPERIOR COMPLETO|              3|      CASADO(A)|          2|      PRETA|        232|      POLICIAL CIVIL|             1270629.01|               4|      NÃO ELEITO|           N|               S|                      -1|6012745020226080000|                           2|                    DEFERIDO|                         2|                  DEFERIDO|                       SIM|                  Válido|                        2|                 Deferido|              S|\n",
      "|21/01/2023|2023-01-30 18:38:33|       2022|              2|ELEIÇÃO ORDINÁRIA|       1|       546|Eleições Gerais E...|02/10/2022|      ESTADUAL|   AP|   AP|            AMAPÁ|       7|DEPUTADO ESTADUAL| 30001604784|       18444|PAULO JORGE CUNHA...|PAULO CUNHA COLET...|             #NULO#|     15959848287|NÃO DIVULGÁVEL|                     12|                   APTO|                       2|                DEFERIDO|      FEDERAÇÃO|        18|         REDE|REDE SUSTENTABILI...|           3| Federação PSOL REDE|     PSOL/REDE|              PSOL/REDE| 30001681259|      FEDERAÇÃO|              PSOL/REDE|               1| BRASILEIRA NATA|              PA|                     -3|               BRAGANÇA|   20/05/1963|                 59|                   2566882550|        2|MASCULINO|                8|   SUPERIOR COMPLETO|              3|      CASADO(A)|          3|      PARDA|        266|PROFESSOR DE ENSI...|             1270629.01|               5|        SUPLENTE|           N|               N|                      -1|6002961420226030000|                           2|                    DEFERIDO|                         2|                  DEFERIDO|                       SIM|                  Válido|                        2|                 Deferido|              S|\n",
      "|21/01/2023|2023-01-30 18:38:33|       2022|              2|ELEIÇÃO ORDINÁRIA|       1|       546|Eleições Gerais E...|02/10/2022|      ESTADUAL|   SE|   SE|          SERGIPE|       7|DEPUTADO ESTADUAL|260001711846|       14111|   GILENO DOS SANTOS|GILENO PAO FILHO ...|             #NULO#|     53210581568|NÃO DIVULGÁVEL|                     12|                   APTO|                       2|                DEFERIDO|PARTIDO ISOLADO|        14|          PTB|PARTIDO TRABALHIS...|          -1|              #NULO#|        #NULO#|                 #NULO#|260001685031|PARTIDO ISOLADO|                    PTB|               1| BRASILEIRA NATA|              SE|                     -3|               ESTÂNCIA|   17/02/1968|                 54|                   4910862194|        2|MASCULINO|                4|ENSINO FUNDAMENTA...|              1|    SOLTEIRO(A)|          2|      PRETA|        999|              OUTROS|             1270629.01|               4|      NÃO ELEITO|           N|               S|                      -1|6009257320226250000|                           2|                    DEFERIDO|                         2|                  DEFERIDO|                       SIM|                  Válido|                        2|                 Deferido|              S|\n",
      "|21/01/2023|2023-01-30 18:38:33|       2022|              2|ELEIÇÃO ORDINÁRIA|       1|       546|Eleições Gerais E...|02/10/2022|      ESTADUAL|   AM|   AM|         AMAZONAS|       7|DEPUTADO ESTADUAL| 40001618475|       44666|GEORGE AUGUSTO MO...|      DR GEORGE LINS|             #NULO#|     72510250272|NÃO DIVULGÁVEL|                     12|                   APTO|                       2|                DEFERIDO|PARTIDO ISOLADO|        44|        UNIÃO|        UNIÃO BRASIL|          -1|              #NULO#|        #NULO#|                 #NULO#| 40001682112|PARTIDO ISOLADO|                  UNIÃO|               1| BRASILEIRA NATA|              AM|                     -3|                 MANAUS|   23/12/1982|                 40|                  22169342224|        2|MASCULINO|                8|   SUPERIOR COMPLETO|              3|      CASADO(A)|          3|      PARDA|        111|              MÉDICO|             1270629.01|               2|   ELEITO POR QP|           N|               S|                      -1|6005011620226040000|                           2|                    DEFERIDO|                         2|                  DEFERIDO|                       SIM|                  Válido|                        2|                 Deferido|              S|\n",
      "|21/01/2023|2023-01-30 18:38:33|       2022|              2|ELEIÇÃO ORDINÁRIA|       1|       546|Eleições Gerais E...|02/10/2022|      ESTADUAL|   AP|   AP|            AMAPÁ|       7|DEPUTADO ESTADUAL| 30001604014|       12456|ALDILENE MATOS DE...|      ALDILENE SOUZA|             #NULO#|     43263240234|NÃO DIVULGÁVEL|                     12|                   APTO|                       2|                DEFERIDO|PARTIDO ISOLADO|        12|          PDT|PARTIDO DEMOCRÁTI...|          -1|              #NULO#|        #NULO#|                 #NULO#| 30001681219|PARTIDO ISOLADO|                    PDT|               1| BRASILEIRA NATA|              AP|                     -3|                 MACAPÁ|   08/07/1970|                 52|                   1402702569|        4| FEMININO|                8|   SUPERIOR COMPLETO|              3|      CASADO(A)|          1|     BRANCA|        277|            DEPUTADO|             1270629.01|               3|ELEITO POR MÉDIA|           S|               N|                      -1|6002606920226030000|                           2|                    DEFERIDO|                         2|                  DEFERIDO|                       SIM|                  Válido|                        2|                 Deferido|              S|\n",
      "|21/01/2023|2023-01-30 18:38:33|       2022|              2|ELEIÇÃO ORDINÁRIA|       1|       546|Eleições Gerais E...|02/10/2022|      ESTADUAL|   BA|   BA|            BAHIA|       7|DEPUTADO ESTADUAL| 50001610388|       51200|SIMONE SANTOS SIL...|MISSIONARIA SIMON...|             #NULO#|     78498600553|NÃO DIVULGÁVEL|                     12|                   APTO|                       2|                DEFERIDO|PARTIDO ISOLADO|        51|     PATRIOTA|            PATRIOTA|          -1|              #NULO#|        #NULO#|                 #NULO#| 50001681500|PARTIDO ISOLADO|               PATRIOTA|               1| BRASILEIRA NATA|              BA|                     -3|               SALVADOR|   05/12/1978|                 44|                  84274510540|        4| FEMININO|                6|ENSINO MÉDIO COMP...|              3|      CASADO(A)|          1|     BRANCA|        257|          EMPRESÁRIO|             1270629.01|               5|        SUPLENTE|           N|               N|                      -1|6012812620226050000|                           2|                    DEFERIDO|                         2|                  DEFERIDO|                       SIM|                  Válido|                        2|                 Deferido|              S|\n",
      "|21/01/2023|2023-01-30 18:38:33|       2022|              2|ELEIÇÃO ORDINÁRIA|       1|       546|Eleições Gerais E...|02/10/2022|      ESTADUAL|   RJ|   RJ|   RIO DE JANEIRO|       6| DEPUTADO FEDERAL|190001603398|        5551|ANA KARLA GUIMARÃ...|KARLA DE LUCAS DO...|             #NULO#|     82226997768|NÃO DIVULGÁVEL|                     12|                   APTO|                       2|                DEFERIDO|PARTIDO ISOLADO|        55|          PSD|PARTIDO SOCIAL DE...|          -1|              #NULO#|        #NULO#|                 #NULO#|190001681204|PARTIDO ISOLADO|                    PSD|               1| BRASILEIRA NATA|              MG|                     -3|           JUIZ DE FORA|   14/04/1965|                 57|                  24050940361|        4| FEMININO|                8|   SUPERIOR COMPLETO|              3|      CASADO(A)|          1|     BRANCA|        171|JORNALISTA E REDATOR|             3176572.53|               5|        SUPLENTE|           N|               S|                      -1|6010171920226190000|                           2|                    DEFERIDO|                         2|                  DEFERIDO|                       SIM|                  Válido|                        2|                 Deferido|              S|\n",
      "+----------+-------------------+-----------+---------------+-----------------+--------+----------+--------------------+----------+--------------+-----+-----+-----------------+--------+-----------------+------------+------------+--------------------+--------------------+-------------------+----------------+--------------+-----------------------+-----------------------+------------------------+------------------------+---------------+----------+-------------+--------------------+------------+--------------------+--------------+-----------------------+------------+---------------+-----------------------+----------------+----------------+----------------+-----------------------+-----------------------+-------------+-------------------+-----------------------------+---------+---------+-----------------+--------------------+---------------+---------------+-----------+-----------+-----------+--------------------+-----------------------+----------------+----------------+------------+----------------+------------------------+-------------------+----------------------------+----------------------------+--------------------------+--------------------------+--------------------------+------------------------+-------------------------+-------------------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "arquivo = '../ProjetoSparkKB/Dados/Candidato/consulta_cand_2022_BRASIL.csv'\n",
    "\n",
    "dfExemplo04 = spark.read.options(header='True'\n",
    "                                 , inferSchema='True'\n",
    "                                 , delimiter=';'\n",
    "                                 , encoding=\"windows-1252\") \\\n",
    "                                 .csv(arquivo)\n",
    "\n",
    "dfExemplo04.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b5fd7c",
   "metadata": {},
   "source": [
    "# 03.7 - Definindo a Estrutura de um DataFrame e Importar CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c643da4b",
   "metadata": {},
   "source": [
    "** Documentação: https://sqlrelease.com/spark-read-file-with-special-characters-using-pyspark\n",
    "\n",
    "** Documentação: https://sparkbyexamples.com/pyspark/pyspark-sql-types-datatype-with-examples/\n",
    "\n",
    "** Documentação: https://spark.apache.org/docs/latest/sql-ref-datatypes.html\n",
    "\n",
    "** Documentação: https://sparkbyexamples.com/pyspark/pyspark-date_format-convert-date-to-string-format/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fdd716",
   "metadata": {},
   "source": [
    "### O arquivo \"indicador_homocidio.csv\" foi criado com a coluna Data do tipo \"Data\"\n",
    "### O que permitiu a criação do DataFrame com a coluna Data do tipo DateType()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "6a003dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CodUf: string (nullable = true)\n",
      " |-- TipoCrime: string (nullable = true)\n",
      " |-- Quantidade: integer (nullable = true)\n",
      " |-- Data: date (nullable = true)\n",
      "\n",
      "+-------------------+----------------+----------+----------+\n",
      "|              CodUf|       TipoCrime|Quantidade|      Data|\n",
      "+-------------------+----------------+----------+----------+\n",
      "|            Roraima|Homicídio doloso|      1389|2023-01-28|\n",
      "|              Amapá|Homicídio doloso|      1948|2023-01-29|\n",
      "|               Acre|Homicídio doloso|      2007|2023-01-30|\n",
      "|          Tocantins|Homicídio doloso|      2787|2023-01-31|\n",
      "|           Rondônia|Homicídio doloso|      3482|2023-02-01|\n",
      "|   Distrito Federal|Homicídio doloso|      3518|2023-02-02|\n",
      "| Mato Grosso do Sul|Homicídio doloso|      3905|2023-02-03|\n",
      "|              Piauí|Homicídio doloso|      4714|2023-02-04|\n",
      "|     Santa Catarina|Homicídio doloso|      5832|2023-02-05|\n",
      "|        Mato Grosso|Homicídio doloso|      6920|2023-02-06|\n",
      "|            Sergipe|Homicídio doloso|      6970|2023-02-07|\n",
      "|           Amazonas|Homicídio doloso|      8590|2023-02-08|\n",
      "|     Espírito Santo|Homicídio doloso|      8695|2023-02-09|\n",
      "|            Paraíba|Homicídio doloso|      8902|2023-02-10|\n",
      "|Rio Grande do Norte|Homicídio doloso|     10242|2023-02-11|\n",
      "|            Alagoas|Homicídio doloso|     10267|2023-02-12|\n",
      "|           Maranhão|Homicídio doloso|     13412|2023-02-13|\n",
      "|              Goiás|Homicídio doloso|     14512|2023-02-14|\n",
      "|             Paraná|Homicídio doloso|     15708|2023-02-15|\n",
      "|  Rio Grande do Sul|Homicídio doloso|     16995|2023-02-16|\n",
      "+-------------------+----------------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "arquivo = '../ProjetoSparkKB/Dados/IndicadorSegurancaPublica/indicador_homocidio.csv'\n",
    "\n",
    "\n",
    "schema = StructType() \\\n",
    "      .add(\"CodUf\",StringType(),True) \\\n",
    "      .add(\"TipoCrime\",StringType(),True) \\\n",
    "      .add(\"Quantidade\",IntegerType(),True) \\\n",
    "      .add(\"Data\",DateType(),True) \\\n",
    "\n",
    "\n",
    "df_with_schema = spark.read.options(header='True'\n",
    "                                    , inferSchema='False'\n",
    "                                    , delimiter=';'\n",
    "                                    , encoding=\"windows-1252\") \\\n",
    "                                    .schema(schema) \\\n",
    "                                    .csv(arquivo)\n",
    "\n",
    "df_with_schema.printSchema()\n",
    "\n",
    "df_with_schema.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fa0283",
   "metadata": {},
   "source": [
    "# 04 - Trabalhando com Datas - Converte coluna String (DD/MM/AAA) para Date (AAAAMMDD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2643a2",
   "metadata": {},
   "source": [
    "### O arquivo \"indicador_homocidio_2.csv\" foi criado com a coluna Data do tipo \"Geral\"\n",
    "### Nesse caso, vamos precisar criar o DataFrame com a coluna Data do tipo StringType() e em seguida realizar a conversão da coluna para o tipo Date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6218479e",
   "metadata": {},
   "source": [
    "* Trabalhando com Datas\n",
    "\n",
    "** Documentação: https://spark.apache.org/docs/latest/sql-ref-datetime-pattern.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "f6a5f83d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------------+----------+----------+\n",
      "|              CodUf|       TipoCrime|Quantidade|      Data|\n",
      "+-------------------+----------------+----------+----------+\n",
      "|            Roraima|Homicídio doloso|      1389|28/01/2023|\n",
      "|              Amapá|Homicídio doloso|      1948|29/01/2023|\n",
      "|               Acre|Homicídio doloso|      2007|30/01/2023|\n",
      "|          Tocantins|Homicídio doloso|      2787|31/01/2023|\n",
      "|           Rondônia|Homicídio doloso|      3482|01/02/2023|\n",
      "|   Distrito Federal|Homicídio doloso|      3518|02/02/2023|\n",
      "| Mato Grosso do Sul|Homicídio doloso|      3905|03/02/2023|\n",
      "|              Piauí|Homicídio doloso|      4714|04/02/2023|\n",
      "|     Santa Catarina|Homicídio doloso|      5832|05/02/2023|\n",
      "|        Mato Grosso|Homicídio doloso|      6920|06/02/2023|\n",
      "|            Sergipe|Homicídio doloso|      6970|07/02/2023|\n",
      "|           Amazonas|Homicídio doloso|      8590|08/02/2023|\n",
      "|     Espírito Santo|Homicídio doloso|      8695|09/02/2023|\n",
      "|            Paraíba|Homicídio doloso|      8902|10/02/2023|\n",
      "|Rio Grande do Norte|Homicídio doloso|     10242|11/02/2023|\n",
      "|            Alagoas|Homicídio doloso|     10267|12/02/2023|\n",
      "|           Maranhão|Homicídio doloso|     13412|13/02/2023|\n",
      "|              Goiás|Homicídio doloso|     14512|14/02/2023|\n",
      "|             Paraná|Homicídio doloso|     15708|15/02/2023|\n",
      "|  Rio Grande do Sul|Homicídio doloso|     16995|16/02/2023|\n",
      "+-------------------+----------------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "------------------------------ ESTRUTURA ANTES DA CONVERSÃO ------------------------------\n",
      "root\n",
      " |-- CodUf: string (nullable = true)\n",
      " |-- TipoCrime: string (nullable = true)\n",
      " |-- Quantidade: integer (nullable = true)\n",
      " |-- Data: string (nullable = true)\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "------------------------------ ESTRUTURA DEPOIS DA CONVERSÃO ------------------------------\n",
      "root\n",
      " |-- CodUf: string (nullable = true)\n",
      " |-- TipoCrime: string (nullable = true)\n",
      " |-- Quantidade: integer (nullable = true)\n",
      " |-- Data: date (nullable = true)\n",
      "\n",
      "+-------------------+----------------+----------+----------+\n",
      "|              CodUf|       TipoCrime|Quantidade|      Data|\n",
      "+-------------------+----------------+----------+----------+\n",
      "|            Roraima|Homicídio doloso|      1389|2023-01-28|\n",
      "|              Amapá|Homicídio doloso|      1948|2023-01-29|\n",
      "|               Acre|Homicídio doloso|      2007|2023-01-30|\n",
      "|          Tocantins|Homicídio doloso|      2787|2023-01-31|\n",
      "|           Rondônia|Homicídio doloso|      3482|2023-02-01|\n",
      "|   Distrito Federal|Homicídio doloso|      3518|2023-02-02|\n",
      "| Mato Grosso do Sul|Homicídio doloso|      3905|2023-02-03|\n",
      "|              Piauí|Homicídio doloso|      4714|2023-02-04|\n",
      "|     Santa Catarina|Homicídio doloso|      5832|2023-02-05|\n",
      "|        Mato Grosso|Homicídio doloso|      6920|2023-02-06|\n",
      "|            Sergipe|Homicídio doloso|      6970|2023-02-07|\n",
      "|           Amazonas|Homicídio doloso|      8590|2023-02-08|\n",
      "|     Espírito Santo|Homicídio doloso|      8695|2023-02-09|\n",
      "|            Paraíba|Homicídio doloso|      8902|2023-02-10|\n",
      "|Rio Grande do Norte|Homicídio doloso|     10242|2023-02-11|\n",
      "|            Alagoas|Homicídio doloso|     10267|2023-02-12|\n",
      "|           Maranhão|Homicídio doloso|     13412|2023-02-13|\n",
      "|              Goiás|Homicídio doloso|     14512|2023-02-14|\n",
      "|             Paraná|Homicídio doloso|     15708|2023-02-15|\n",
      "|  Rio Grande do Sul|Homicídio doloso|     16995|2023-02-16|\n",
      "+-------------------+----------------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "arquivo = '../ProjetoSparkKB/Dados/IndicadorSegurancaPublica/indicador_homocidio_2.csv'\n",
    "\n",
    "schema = StructType() \\\n",
    "      .add(\"CodUf\",StringType(),True) \\\n",
    "      .add(\"TipoCrime\",StringType(),True) \\\n",
    "      .add(\"Quantidade\",IntegerType(),True) \\\n",
    "      .add(\"Data\",StringType(),True) \\\n",
    "\n",
    "df_with_schema2 = spark.read.options(header='True', inferSchema='False', delimiter=';', encoding=\"windows-1252\") \\\n",
    "      .schema(schema) \\\n",
    "      .csv(arquivo)\n",
    "\n",
    "df_with_schema2.show()\n",
    "\n",
    "print('------------------------------ ESTRUTURA ANTES DA CONVERSÃO ------------------------------')\n",
    "\n",
    "df_with_schema2.printSchema()\n",
    "\n",
    "print('------------------------------------------------------------------------------------------')\n",
    "\n",
    "df_with_schema2 = df_with_schema2.withColumn('Data', to_date(date_format(unix_timestamp(df_with_schema2.Data , \"dd/mm/yyyy\").cast(\"timestamp\"),\"yyyy-mm-dd\")))\n",
    "\n",
    "print('------------------------------ ESTRUTURA DEPOIS DA CONVERSÃO ------------------------------')\n",
    "\n",
    "df_with_schema2.printSchema()\n",
    "\n",
    "df_with_schema2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2843443",
   "metadata": {},
   "source": [
    "# 04.1 - Trabalhando com Datas - A partir de uma coluna de Data, criar outra de Ano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd920230",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_with_schema2 = df_with_schema2.withColumn(\"Ano\", date_format(col(\"Data\"), \"y\"))\n",
    "\n",
    "\n",
    "df_with_schema2.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57e7b1d",
   "metadata": {},
   "source": [
    "# 04.2 - Trabalhando com Datas - A partir de uma coluna de Data, criar outra de Mês"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d43cc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_with_schema2 = df_with_schema2.withColumn(\"NumMes\", date_format(col(\"Data\"), \"M\"))\n",
    "\n",
    "df_with_schema2 = df_with_schema2.withColumn(\"NomMes\", date_format(col(\"Data\"), \"L\"))\n",
    "\n",
    "\n",
    "df_with_schema2.printSchema()\n",
    "\n",
    "df_with_schema2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7051821d",
   "metadata": {},
   "source": [
    "# 04.3 - Trabalhando com Datas - A partir de uma coluna de Data, criar outra de Dia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669934e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df_with_schema2 = df_with_schema2.withColumn(\"NumDiaAno\", date_format(col(\"Data\"), \"D\"))\n",
    "\n",
    "df_with_schema2 = df_with_schema2.withColumn(\"NumDiaMes\", date_format(col(\"Data\"), \"d\"))\n",
    "\n",
    "df_with_schema2.printSchema()\n",
    "\n",
    "df_with_schema2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19d56a0",
   "metadata": {},
   "source": [
    "# 05 - Trabalhando com Arquivos Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419f7f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#arquivoDestino = '../ProjetoSparkKB/Dados/Parquet/indicador_homocidio.parquet'\n",
    "\n",
    "#df_with_schema3.write.mode(\"overwrite\").parquet(arquivoDestino)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a5d7ca",
   "metadata": {},
   "source": [
    "# 06 - Comando Semelhante ao DataFrame.info() do Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4064af57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_schema3.summary().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b440ad",
   "metadata": {},
   "source": [
    "# 04 - Transformando o DataFrame Spark em Tabela Temporária"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157f47a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('teste')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9b9a6e",
   "metadata": {},
   "source": [
    "# 05 - Consultando a Estrutura do DataFrame Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1519c70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c403b4",
   "metadata": {},
   "source": [
    "# 06 - Lendo a Tabela e Transformando em outro DataFrame Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321f7f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = spark.sql(\"\"\"\n",
    "SELECT DT_GERACAO \n",
    "FROM TESTE\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3dcbab4",
   "metadata": {},
   "source": [
    "# 07 - Convertendo o DataType de uma Coluna de um DataFrame Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adee011",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.withColumn(\"DT_GERACAO\", df2[\"DT_GERACAO\"].cast(\"timestamp\")).printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81ec42d",
   "metadata": {},
   "source": [
    "# 08 - Convertendo o DataType e Criando uma nova Coluna de um DataFrame Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7358983",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.withColumn(\"DTGERACAO\", df2[\"DT_GERACAO\"].cast(\"timestamp\")).printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d56251",
   "metadata": {},
   "source": [
    "# 09 - Renomeando uma Coluna em DataFrame Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6004d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.withColumnRenamed(\"DT_GERACAO\",\"DT_GERACAO2\").printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81929c4",
   "metadata": {},
   "source": [
    "# 10 - Renomeando Várias Colunas em DataFrame Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce058d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = spark.sql(\"\"\"\n",
    "SELECT DT_GERACAO , HH_GERACAO\n",
    "FROM TESTE\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbf44c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df3.withColumnRenamed(\"DT_GERACAO\",\"DtGeracao\") \\\n",
    "    .withColumnRenamed(\"HH_GERACAO\",\"HrGeracao\")\n",
    "df3.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2902ee0",
   "metadata": {},
   "source": [
    "# 11 - Ordenando um DataFrame Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a580782b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = spark.sql(\"\"\"\n",
    "SELECT SG_UF , NM_URNA_CANDIDATO\n",
    "FROM TESTE\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65525fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0049a15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.sort(\"SG_UF\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1346d0",
   "metadata": {},
   "source": [
    "# 11.1 - Ordenando um DataFrame Spark por Várias Colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c228be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.sort(\"SG_UF\",\"NM_URNA_CANDIDATO\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a99ca4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df4.sort(col(\"SG_UF\"),col(\"NM_URNA_CANDIDATO\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0616911e",
   "metadata": {},
   "source": [
    "# 12 - Agrupando um DataFrame Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adea42a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.groupBy(\"SG_UF\").count().show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b464158c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = spark.sql(\"\"\"\n",
    "SELECT SG_UF , NM_URNA_CANDIDATO, SQ_CANDIDATO\n",
    "FROM TESTE\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5593e7a3",
   "metadata": {},
   "source": [
    "# 13 - Funções de Agrupamento (Count(), Sum(), Min(), Max() e Mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b043be67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.groupBy(\"SG_UF\") \\\n",
    "    .agg(count(\"SQ_CANDIDATO\").alias(\"count_SQ_CANDIDATO\"), \\\n",
    "         sum(\"SQ_CANDIDATO\").alias(\"sum_SQ_CANDIDATO\"), \\\n",
    "         avg(\"SQ_CANDIDATO\").alias(\"avg_SQ_CANDIDATO\"), \\\n",
    "         min(\"SQ_CANDIDATO\").alias(\"min_SQ_CANDIDATO\"), \\\n",
    "         max(\"SQ_CANDIDATO\").alias(\"max_SQ_CANDIDATO\") \\\n",
    "     ) \\\n",
    "    .show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
